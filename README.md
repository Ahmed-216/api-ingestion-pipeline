# FiliÃ¨re Data Template

Ce repo est un template qui sert Ã  cadrer le dÃ©veloppement de pipelines python par l'Ã©quipe data. 

## Utilisation comme Template GitHub 
1. Cliquer sur le bouton `Use this template` en haut de ce repo
2. Choisir `Create a new repository`
3. Donner un nom au nouveau projet
4. Cloner le nouveau repo

## Personnalisation du Projet

AprÃ¨s avoir clonÃ© le template, il faut personnaliser le projet :

1. **Renommer le package** : Modifier `name` dans `pyproject.toml`
2. **Mettre Ã  jour la description** : Modifier `description` dans `pyproject.toml`
3. **Renommer le dossier principal** : Renommer `filiere_data_template/` vers le nom du projet
4. **Mettre Ã  jour les imports** : Remplacer `filiere_data_template` par le nom de package dans tous les fichiers Python


## ğŸ“ Structure du Projet

```
data-pipeline-template/
â”œâ”€â”€ filiere_data_template/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py              # Configuration et setup 
â”‚   â”œâ”€â”€ runner.py              # Script d'orchestration 
â”‚   â”œâ”€â”€ scripts/               
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ script_1.py        # Script d'exemple 
â”‚   â”‚   â””â”€â”€ script_2.py        # Scripts additionnels...
â”‚   â”œâ”€â”€ sql/
â”‚   â”‚   â””â”€â”€ query.sql          # RequÃªtes SQL
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ base.py            # Classe avec fonctionnalitÃ©s communes
â”œâ”€â”€ logs/                      # Fichiers de logs 
â”œâ”€â”€ notebooks/                 # Notebooks Jupyter pour l'analyse
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_script_1.py       # Exemples de tests
â””â”€â”€ .env                       # Identifiants de connexion
â””â”€â”€ .gitignore                 # Fichiers Ã  ne pas partager sur Git 
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ pytest.ini
â””â”€â”€ README.md
â””â”€â”€ run.py                     # Script d'exÃ©cution 

```

## ğŸ› ï¸ Installation & Configuration

1. **Installer les dÃ©pendances**
   ```bash
   poetry install
   ```

2. **Configurer les variables d'environnement**
   CrÃ©er un fichier `.env` Ã  la racine du projet :
   ```python
   # Connexion base de donnÃ©es
   ADDRESS_USER_DEV=mysql://user:password@192.168.20.92:33068
   ADDRESS_USER_DEV=mysql://user:password@192.168.20.91:33068
   ADRESS_USER_PROD=mysql://user:password@sql-prod.carbone4h.com:33067
   ```
   remplacer `user` et `password` avec les identifiants de connexion Ã  la base de donnÃ©es

3. **Mettre Ã  jour la configuration**
   Modifier `filiere_data_template/config.py` pour correspondre Ã  ton environnement :
   ```python
   ENV = "DEV"  # ou "PREPROD", "PROD"
   DB_PROD = "ta_base_production"
   ```

##  Utilisation

### ExÃ©cuter un Script

```bash
# ExÃ©cuter un script spÃ©cifique
poetry run python run.py script_1

# ExÃ©cuter le pipeline entier
poetry run python run.py all
```

### CrÃ©er un Nouveau Script

1. **CrÃ©er un nouveau fichier de script** dans `filiere_data_template/scripts/`

2. **Ajouter les requÃªte SQL** dans `filiere_data_template/sql/`

3. **CrÃ©er des tests** dans `tests/`

4. **Ajouter les nouveaux packages python importÃ©s**  
```bash
poetry add <package_name> # e.g poetry add pandas
```

## Tests

### ExÃ©cuter les Tests

```bash
# ExÃ©cuter tous les tests
poetry run pytest

# ExÃ©cuter un fichier de test spÃ©cifique
poetry run pytest tests/test_script_1.py
```
**NB :** Dans l'exemple fourni (`script_1`) l'exÃ©cution de tests est incluse au run du script.

## Fichiers log

Chaque script crÃ©e automatiquement un fichier de log avec le mÃªme nom dans le rÃ©pertoire `logs/` :


### Fichier de Configuration

ParamÃ¨tres clÃ©s dans `filiere_data_template/config.py` :

```python
ENV = "DEV"                    # Environnement (DEV/PREPROD/PROD)
DB_STAGING = "staging"         # Nom de la base de staging
DB_PROD = "production"         # Nom de la base de production
LOG_LEVEL = "INFO"             # Niveau de log pour l'affichage
```

## Bonnes Pratiques

1. **HÃ©riter de BaseClass** : Tous les scripts doivent hÃ©riter de `BaseClass` qui contients les paramÃ¨tres de connexions Ã  la bdd et des mÃ©thodes communes Ã  diffÃ©rents scripts.
2. **Suivre le pattern ETL** : Extract â†’ Transform â†’ Load
3. **Ajouter des logs** : Logger les Ã©tapes importantes
4. **Ã‰crire des tests** : Inclure des tests unitaires pour tester le comportement des fonctions et d'intÃ©gration pour tester les donnÃ©es transformÃ©es avant l'intÃ©gration Ã  la bdd.
5. **Utiliser les branches et les tags sur git** : Utiliser des branches sÃ©parÃ©es pour les fonctionalitÃ©s dÃ©veloppÃ©es et les tags git pour historiser les diffÃ©rentes versions du code.





